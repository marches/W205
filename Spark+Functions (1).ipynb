{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import udf, from_json, split, col, regexp_replace, avg, trim\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Wines extract\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in a CSV format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\")\\\n",
    "    .option(\"subscribe\",\"wines\")\\\n",
    "    .option(\"startingOffsets\", \"earliest\")\\\n",
    "    .option(\"endingOffsets\", \"latest\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cache() method, Spark provides an optimization mechanism to store the intermediate computation of an RDD, DataFrame, and Dataset so they can be reused in subsequent actions(reusing the RDD, Dataframe, and Dataset computation result’s).\n",
    "\n",
    "This therefore curbs the following warning from showing up when performing each computation: WARN CachedKafkaConsumer: CachedKafkaConsumer is not running in UninterruptibleThread. It may hang when CachedKafkaConsumer's methods are interrupted because of KAFKA-1894."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_value_as_strings=df.selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|7.4,0.7,0,1.9,0.0...|\n",
      "|7.8,0.88,0,2.6,0....|\n",
      "|7.8,0.76,0.04,2.3...|\n",
      "|11.2,0.28,0.56,1....|\n",
      "|7.4,0.7,0,1.9,0.0...|\n",
      "|7.4,0.66,0,1.8,0....|\n",
      "|7.9,0.6,0.06,1.6,...|\n",
      "|7.3,0.65,0,1.2,0....|\n",
      "|7.8,0.58,0.02,2,0...|\n",
      "|7.5,0.5,0.36,6.1,...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_value_as_strings.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to not see a truncated view of the column values, you can use a \"false\" argument as the second argument in the show() method. The argument conveys trucate=false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|value                                                |\n",
      "+-----------------------------------------------------+\n",
      "    |0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\n",
      "    |0.88,0,2.6,0.098,25,67,0.9968,3.2,0.68,9.8,5\n",
      " |.8,0.76,0.04,2.3,0.092,15,54,0.997,3.26,0.65,9.8,5\n",
      "|11.2,0.28,0.56,1.9,0.075,17,60,0.998,3.16,0.58,9.8,6\n",
      "    |0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\n",
      "   |,0.66,0,1.8,0.075,13,40,0.9978,3.51,0.56,9.4,5\n",
      "  |9,0.6,0.06,1.6,0.069,15,59,0.9964,3.3,0.46,9.4,5\n",
      "    |0.65,0,1.2,0.065,15,21,0.9946,3.39,0.47,10,7\n",
      "   |,0.58,0.02,2,0.073,9,18,0.9968,3.36,0.57,9.5,7\n",
      "|7.5,0.5,0.36,6.1,0.071,17,102,0.9978,3.35,0.8,10.5,5\n",
      "+-----------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_value_as_strings.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some white space issues with the last column that is causing the output format to be out of expected order. We can use the *trim* function for this while reading in the last column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_df = df_value_as_strings.withColumn(\"fixed_acidity\",split(col(\"value\"),\",\").getItem(0))\\\n",
    "                              .withColumn(\"volatile_acidity\",split(col(\"value\"),\",\").getItem(1))\\\n",
    "                              .withColumn(\"citric_acid\",split(col(\"value\"),\",\").getItem(2))\\\n",
    "                              .withColumn(\"residual+sugar\",split(col(\"value\"),\",\").getItem(3))\\\n",
    "                              .withColumn(\"chlorides\",split(col(\"value\"),\",\").getItem(4))\\\n",
    "                              .withColumn(\"free_sulfur_dioxide\",split(col(\"value\"),\",\").getItem(5))\\\n",
    "                              .withColumn(\"total_sulfur_dioxide\",split(col(\"value\"),\",\").getItem(6))\\\n",
    "                              .withColumn(\"density\",split(col(\"value\"),\",\").getItem(7))\\\n",
    "                              .withColumn(\"pH\",split(col(\"value\"),\",\").getItem(8))\\\n",
    "                              .withColumn(\"sulphates\",split(col(\"value\"),\",\").getItem(9))\\\n",
    "                              .withColumn(\"alcohol\",split(col(\"value\"),\",\").getItem(10))\\\n",
    "                              .withColumn(\"quality\",trim(split(col(\"value\"),\",\").getItem(11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|               value|fixed_acidity|volatile_acidity|citric_acid|residual+sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+--------------------+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|7.4,0.7,0,1.9,0.0...|          7.4|             0.7|          0|           1.9|    0.076|                 11|                  34| 0.9978|3.51|     0.56|    9.4|     5\n",
      "|7.8,0.88,0,2.6,0....|          7.8|            0.88|          0|           2.6|    0.098|                 25|                  67| 0.9968| 3.2|     0.68|    9.8|     5\n",
      "|7.8,0.76,0.04,2.3...|          7.8|            0.76|       0.04|           2.3|    0.092|                 15|                  54|  0.997|3.26|     0.65|    9.8|     5\n",
      "|11.2,0.28,0.56,1....|         11.2|            0.28|       0.56|           1.9|    0.075|                 17|                  60|  0.998|3.16|     0.58|    9.8|     6\n",
      "|7.4,0.7,0,1.9,0.0...|          7.4|             0.7|          0|           1.9|    0.076|                 11|                  34| 0.9978|3.51|     0.56|    9.4|     5\n",
      "|7.4,0.66,0,1.8,0....|          7.4|            0.66|          0|           1.8|    0.075|                 13|                  40| 0.9978|3.51|     0.56|    9.4|     5\n",
      "|7.9,0.6,0.06,1.6,...|          7.9|             0.6|       0.06|           1.6|    0.069|                 15|                  59| 0.9964| 3.3|     0.46|    9.4|     5\n",
      "|7.3,0.65,0,1.2,0....|          7.3|            0.65|          0|           1.2|    0.065|                 15|                  21| 0.9946|3.39|     0.47|     10|     7\n",
      "|7.8,0.58,0.02,2,0...|          7.8|            0.58|       0.02|             2|    0.073|                  9|                  18| 0.9968|3.36|     0.57|    9.5|     7\n",
      "|7.5,0.5,0.36,6.1,...|          7.5|             0.5|       0.36|           6.1|    0.071|                 17|                 102| 0.9978|3.35|      0.8|   10.5|     5\n",
      "+--------------------+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations and Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trailing space after the last value has still not gone. To look at what the character is, we can use the *head* function to show us the top row only in a different format than *show*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\\r', fixed_acidity='7.4', volatile_acidity='0.7', citric_acid='0', residual+sugar='1.9', chlorides='0.076', free_sulfur_dioxide='11', total_sulfur_dioxide='34', density='0.9978', pH='3.51', sulphates='0.56', alcohol='9.4', quality='5\\r')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a '\\r' which indicates an escape character. This is because I did not split the lines in the csv file as I put through the kafka topic. I will go and repeat the step of ingesting data into kafka. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_df = wines_df.withColumn(\"quality_formatted\",regexp_replace(col(\"quality\"), \"\\r\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\\r', fixed_acidity='7.4', volatile_acidity='0.7', citric_acid='0', residual+sugar='1.9', chlorides='0.076', free_sulfur_dioxide='11', total_sulfur_dioxide='34', density='0.9978', pH='3.51', sulphates='0.56', alcohol='9.4', quality='5\\r', quality_formatted='5')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the 'value' or 'quality' columns anymore so we will *drop* them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fixed_acidity: string, volatile_acidity: string, citric_acid: string, residual+sugar: string, chlorides: string, free_sulfur_dioxide: string, total_sulfur_dioxide: string, density: string, pH: string, sulphates: string, alcohol: string, quality_formatted: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_df.drop(\"value\",\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4,5\\r', fixed_acidity='7.4', volatile_acidity='0.7', citric_acid='0', residual+sugar='1.9', chlorides='0.076', free_sulfur_dioxide='11', total_sulfur_dioxide='34', density='0.9978', pH='3.51', sulphates='0.56', alcohol='9.4', quality='5\\r', quality_formatted='5')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, the value still remained. This is because spark Dataframes, as well as datasets and RDDs (resilient distributed datasets), are considered immutable storage. Immutability is defined as unchangeable.\n",
    "\n",
    "What you can do instead is to assign that to a new Dataframe like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wines_df_revised = wines_df.drop(\"value\",\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(fixed_acidity='7.4', volatile_acidity='0.7', citric_acid='0', residual+sugar='1.9', chlorides='0.076', free_sulfur_dioxide='11', total_sulfur_dioxide='34', density='0.9978', pH='3.51', sulphates='0.56', alcohol='9.4', quality_formatted='5')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_df_revised.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used *head* and *first* which show the top row of the Dataframe. We could also do a *show(1)* to get the same result (in a slightly different output format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "|fixed_acidity|volatile_acidity|citric_acid|residual+sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality_formatted|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "|          7.4|             0.7|          0|           1.9|    0.076|                 11|                  34| 0.9978|3.51|     0.56|    9.4|                5|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *select* function let's you select certain columns, much the same way that sql did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[density: string, quality_formatted: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_df_revised.select(\"density\", \"quality_formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark does Lazy Evaluation so the transformation above, with select, is just maintained as a record of which operation is being called (through DAG). If we did a *show()* (or a *collect()*) function after this transformation, spark would then evaluate the operation to give a result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|density|quality_formatted|\n",
      "+-------+-----------------+\n",
      "| 0.9978|                5|\n",
      "| 0.9968|                5|\n",
      "|  0.997|                5|\n",
      "|  0.998|                6|\n",
      "| 0.9978|                5|\n",
      "| 0.9978|                5|\n",
      "| 0.9964|                5|\n",
      "| 0.9946|                7|\n",
      "| 0.9968|                7|\n",
      "| 0.9978|                5|\n",
      "| 0.9959|                5|\n",
      "| 0.9978|                5|\n",
      "| 0.9943|                5|\n",
      "| 0.9974|                5|\n",
      "| 0.9986|                5|\n",
      "| 0.9986|                5|\n",
      "| 0.9969|                7|\n",
      "| 0.9968|                5|\n",
      "| 0.9974|                4|\n",
      "| 0.9969|                6|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.select(\"density\", \"quality_formatted\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use spark sql, we need to first register our DataFrame as a Temp Table. Then, in all the spark sql commands, this temp table will be referred to for the 'from'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wines_df_revised.registerTempTable('wines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, we will see the spark sql counterpart for all the functions we perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|density|quality_formatted|\n",
      "+-------+-----------------+\n",
      "| 0.9978|                5|\n",
      "| 0.9968|                5|\n",
      "|  0.997|                5|\n",
      "|  0.998|                6|\n",
      "| 0.9978|                5|\n",
      "| 0.9978|                5|\n",
      "| 0.9964|                5|\n",
      "| 0.9946|                7|\n",
      "| 0.9968|                7|\n",
      "| 0.9978|                5|\n",
      "| 0.9959|                5|\n",
      "| 0.9978|                5|\n",
      "| 0.9943|                5|\n",
      "| 0.9974|                5|\n",
      "| 0.9986|                5|\n",
      "| 0.9986|                5|\n",
      "| 0.9969|                7|\n",
      "| 0.9968|                5|\n",
      "| 0.9974|                4|\n",
      "| 0.9969|                6|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select\n",
    "spark.sql(\"select density, quality_formatted from wines\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the unique values of a column, we can use the *distinct()* function after the *select()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|quality_formatted|\n",
      "+-----------------+\n",
      "|                7|\n",
      "|                3|\n",
      "|                8|\n",
      "|                5|\n",
      "|                6|\n",
      "|                4|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.select(\"quality_formatted\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|quality_formatted|\n",
      "+-----------------+\n",
      "|                7|\n",
      "|                3|\n",
      "|                8|\n",
      "|                5|\n",
      "|                6|\n",
      "|                4|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select distinct\n",
    "spark.sql(\"select distinct quality_formatted from wines\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how to select to show only some columns, to see only some rows, we can use *filter()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "|fixed_acidity|volatile_acidity|citric_acid|residual+sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality_formatted|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "|          7.3|            0.65|          0|           1.2|    0.065|                 15|                  21| 0.9946|3.39|     0.47|     10|                7|\n",
      "|          7.8|            0.58|       0.02|             2|    0.073|                  9|                  18| 0.9968|3.36|     0.57|    9.5|                7|\n",
      "|          8.5|            0.28|       0.56|           1.8|    0.092|                 35|                 103| 0.9969| 3.3|     0.75|   10.5|                7|\n",
      "|          8.1|            0.38|       0.28|           2.1|    0.066|                 13|                  30| 0.9968|3.23|     0.73|    9.7|                7|\n",
      "|          7.5|            0.52|       0.16|           1.9|    0.085|                 12|                  35| 0.9968|3.38|     0.62|    9.5|                7|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.filter(wines_df_revised.quality_formatted == \"7\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spark sql, this is achieved with the 'where'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "|fixed_acidity|volatile_acidity|citric_acid|residual+sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality_formatted|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "|          7.3|            0.65|          0|           1.2|    0.065|                 15|                  21| 0.9946|3.39|     0.47|     10|                7|\n",
      "|          7.8|            0.58|       0.02|             2|    0.073|                  9|                  18| 0.9968|3.36|     0.57|    9.5|                7|\n",
      "|          8.5|            0.28|       0.56|           1.8|    0.092|                 35|                 103| 0.9969| 3.3|     0.75|   10.5|                7|\n",
      "|          8.1|            0.38|       0.28|           2.1|    0.066|                 13|                  30| 0.9968|3.23|     0.73|    9.7|                7|\n",
      "|          7.5|            0.52|       0.16|           1.9|    0.085|                 12|                  35| 0.9968|3.38|     0.62|    9.5|                7|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from wines where quality_formatted='7'\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(density)|\n",
      "+------------------+\n",
      "|0.9967466791744831|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.agg(avg(col(\"density\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|avg(CAST(density AS DOUBLE))|\n",
      "+----------------------------+\n",
      "|          0.9967466791744831|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select avg(density) from wines\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of writing an aggregate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(density)|\n",
      "+------------------+\n",
      "|0.9967466791744831|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.agg({\"density\": \"avg\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to see aggregates per levels, we can use a group by, much like in sql. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|quality_formatted|      avg(density)|\n",
      "+-----------------+------------------+\n",
      "|                7|0.9961042713567828|\n",
      "|                3|0.9974640000000001|\n",
      "|                8|0.9952122222222223|\n",
      "|                5|0.9971036270190888|\n",
      "|                6|0.9966150626959255|\n",
      "|                4|0.9965424528301886|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.groupBy(\"quality_formatted\").agg(avg(col(\"density\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------------+\n",
      "|quality_formatted|avg(CAST(density AS DOUBLE))|\n",
      "+-----------------+----------------------------+\n",
      "|                7|          0.9961042713567828|\n",
      "|                3|          0.9974640000000001|\n",
      "|                8|          0.9952122222222223|\n",
      "|                5|          0.9971036270190888|\n",
      "|                6|          0.9966150626959255|\n",
      "|                4|          0.9965424528301886|\n",
      "+-----------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select quality_formatted, avg(density) from wines group by quality_formatted\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also *count* and see what the distribution of our dataset is by quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|quality_formatted|count|\n",
      "+-----------------+-----+\n",
      "|                7|  199|\n",
      "|                3|   10|\n",
      "|                8|   18|\n",
      "|                5|  681|\n",
      "|                6|  638|\n",
      "|                4|   53|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.groupBy(\"quality_formatted\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|quality_formatted|count_per_quality|\n",
      "+-----------------+-----------------+\n",
      "|                7|              199|\n",
      "|                3|               10|\n",
      "|                8|               18|\n",
      "|                5|              681|\n",
      "|                6|              638|\n",
      "|                4|               53|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select quality_formatted, count(1) as count_per_quality from wines group by quality_formatted\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can *orderBy* again very similarly to how you did in sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|quality_formatted|count|\n",
      "+-----------------+-----+\n",
      "|                3|   10|\n",
      "|                8|   18|\n",
      "|                4|   53|\n",
      "|                7|  199|\n",
      "|                6|  638|\n",
      "|                5|  681|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wines_df_revised.groupBy(\"quality_formatted\").count().orderBy(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|quality_formatted|count_per_quality|\n",
      "+-----------------+-----------------+\n",
      "|                3|               10|\n",
      "|                8|               18|\n",
      "|                4|               53|\n",
      "|                7|              199|\n",
      "|                6|              638|\n",
      "|                5|              681|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select quality_formatted, count(1) as count_per_quality from wines group by quality_formatted order by count_per_quality\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the results of these functions can be saved in a separate DataFrame if you need to move forward with that transformation/aggregation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in a JSON format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "brazillian_wines = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"kafka:29092\").option(\"subscribe\",\"brazillian-wines\").option(\"startingOffsets\", \"earliest\").option(\"endingOffsets\", \"latest\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazillian_wines.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again cast the value as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazillian_wines_df=brazillian_wines.selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='{\"id\":4801829,\"name\":\"Luiz Valduga Corte 1\",\"seo_name\":\"luiz-valduga-corte-1-vale-dos-vinhedos\",\"type_id\":1,\"vintage_type\":0,\"is_natural\":false,\"region\":{\"id\":931,\"name\":\"Vale dos Vinhedos\",\"name_en\":\"\",\"seo_name\":\"vale-dos-vinhedos\",\"country\":{\"code\":\"br\",\"name\":\"Brasil\",\"native_name\":\"Brasil\",\"seo_name\":\"brazil\",\"currency\":{\"code\":\"BRL\",\"name\":\"Brazil Reais\",\"prefix\":\"R$\",\"suffix\":null},\"regions_count\":24,\"users_count\":3642678,\"wines_count\":13586,\"wineries_count\":1377,\"most_used_grapes\":[{\"id\":2,\"name\":\"Cabernet Sauvignon\",\"seo_name\":\"cabernet-sauvignon\",\"has_detailed_info\":true,\"wines_count\":727728},{\"id\":10,\"name\":\"Merlot\",\"seo_name\":\"merlot\",\"has_detailed_info\":true,\"wines_count\":512171},{\"id\":5,\"name\":\"Chardonnay\",\"seo_name\":\"chardonnay\",\"has_detailed_info\":true,\"wines_count\":543051}]},\"background_image\":{\"location\":\"//images.vivino.com/regions/backgrounds/XrRrK-skTsOz6SDm_2tKeA.jpg\",\"variations\":{\"large\":\"//thumbs.vivino.com/region_backgrounds/XrRrK-skTsOz6SDm_2tKeA_1280x760.jpg\",\"medium\":\"//thumbs.vivino.com/region_backgrounds/XrRrK-skTsOz6SDm_2tKeA_600x356.jpg\"}}},\"winery\":{\"id\":14965,\"name\":\"Casa Valduga\",\"seo_name\":\"casa-valduga\",\"status\":0},\"taste\":{\"structure\":null,\"flavor\":[{\"group\":\"oak\",\"stats\":{\"count\":9,\"score\":1244,\"mentions_count\":13},\"primary_keywords\":[{\"id\":101,\"name\":\"chocolate\",\"count\":6},{\"id\":117,\"name\":\"café\",\"count\":2},{\"id\":134,\"name\":\"chocolate amargo\",\"count\":1},{\"id\":112,\"name\":\"cravo\",\"count\":1},{\"id\":422,\"name\":\"tabaco\",\"count\":1},{\"id\":275,\"name\":\"chocolate ao leite\",\"count\":1},{\"id\":292,\"name\":\"carvalho\",\"count\":1}],\"secondary_keywords\":[{\"id\":242,\"name\":\"couro\",\"count\":2},{\"id\":384,\"name\":\"fumaça\",\"count\":2}]},{\"group\":\"black_fruit\",\"stats\":{\"count\":8,\"score\":1300,\"mentions_count\":13},\"primary_keywords\":[{\"id\":49,\"name\":\"amora\",\"count\":5},{\"id\":52,\"name\":\"groselha\",\"count\":3},{\"id\":334,\"name\":\"ameixa\",\"count\":3},{\"id\":39,\"name\":\"fruta preta\",\"count\":1},{\"id\":55,\"name\":\"mirtilo\",\"count\":1}]},{\"group\":\"red_fruit\",\"stats\":{\"count\":8,\"score\":1000,\"mentions_count\":10},\"primary_keywords\":[{\"id\":93,\"name\":\"cereja\",\"count\":8},{\"id\":348,\"name\":\"framboesa\",\"count\":1},{\"id\":400,\"name\":\"morango\",\"count\":1}]},{\"group\":\"earth\",\"stats\":{\"count\":5,\"score\":421,\"mentions_count\":5},\"primary_keywords\":[{\"id\":242,\"name\":\"couro\",\"count\":2},{\"id\":384,\"name\":\"fumaça\",\"count\":2},{\"id\":181,\"name\":\"gengibre\",\"count\":1}],\"secondary_keywords\":[{\"id\":134,\"name\":\"chocolate amargo\",\"count\":1},{\"id\":422,\"name\":\"tabaco\",\"count\":1}]},{\"group\":\"non_oak\",\"stats\":{\"count\":5,\"score\":87,\"mentions_count\":0},\"secondary_keywords\":[{\"id\":117,\"name\":\"café\",\"count\":2},{\"id\":384,\"name\":\"fumaça\",\"count\":2},{\"id\":112,\"name\":\"cravo\",\"count\":1},{\"id\":422,\"name\":\"tabaco\",\"count\":1}]},{\"group\":\"spices\",\"stats\":{\"count\":1,\"score\":48,\"mentions_count\":0},\"secondary_keywords\":[{\"id\":112,\"name\":\"cravo\",\"count\":1},{\"id\":181,\"name\":\"gengibre\",\"count\":1}]}]},\"statistics\":{\"status\":\"Normal\",\"ratings_count\":1180,\"ratings_average\":4.6,\"labels_count\":2659,\"vintages_count\":33},\"style\":null,\"has_valid_ratings\":true}')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazillian_wines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To unwrap this JSON, we can use a *map* function and run each row of the DataFrame with the function we pass to the *map()* function. \n",
    "\n",
    "*flatMap()* is also a function with similar capabilities. The difference between *map()* and *flatMap()* is that *flatmap* allows returning 0, 1 or more elements from map function. So a *flatMap* can be used to flatten array elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_wine_details_from_json(row):\n",
    "    wines = json.loads(row.value)\n",
    "    wines_details = {\"id\": wines[\"id\"],\n",
    "                     \"name\": wines[\"name\"],\n",
    "                     \"seo_name\": wines[\"seo_name\"],\n",
    "                     \"is_natural\": wines[\"is_natural\"],\n",
    "                     \"winery_name\": wines[\"winery\"][\"name\"],\n",
    "                     \"ratings_average\": wines[\"statistics\"][\"ratings_average\"],\n",
    "                     \"ratinge_count\": wines[\"statistics\"][\"ratings_count\"]}\n",
    "    return Row(**wines_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can have an for loop to go through all flavor groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazillian_wines_details_df = brazillian_wines_df.rdd.map(extract_wine_details_from_json).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+-------------+---------------+--------------------+---------------+\n",
      "|     id|is_natural|                name|ratinge_count|ratings_average|            seo_name|    winery_name|\n",
      "+-------+----------+--------------------+-------------+---------------+--------------------+---------------+\n",
      "|4801829|     false|Luiz Valduga Corte 1|         1180|            4.6|luiz-valduga-cort...|   Casa Valduga|\n",
      "|1964017|     false|        Gran Reserva|          308|            4.6|        gran-reserva|      Milantino|\n",
      "|1638525|     false|Seival Estate Ses...|         1291|            4.4|seival-estate-ses...|          Miolo|\n",
      "|2571920|     false|Merlot Uvas Desid...|          693|            4.3|uvas-desidratadas...|   Luiz Argenta|\n",
      "|4158362|     false|                Brut|          207|            3.9|                brut|Vinedos Capoani|\n",
      "+-------+----------+--------------------+-------------+---------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brazillian_wines_details_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flavor_details_for_wines(row):\n",
    "    wines = json.loads(row.value)\n",
    "    flavors_list = []\n",
    "    if(\"taste\" in wines.keys()):\n",
    "        if(\"flavor\" in wines[\"taste\"].keys()):\n",
    "            flavors = wines[\"taste\"][\"flavor\"]\n",
    "    \n",
    "    for flavor in flavors:\n",
    "        flavor_row = {\"id\": wines[\"id\"],\n",
    "                      \"wine_name\": wines[\"name\"],\n",
    "                      \"flavor_group\": flavor[\"group\"]}\n",
    "        flavors_list.append(Row(**flavor_row))\n",
    "        \n",
    "    return flavors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine_flavors_df = brazillian_wines_df.rdd.flatMap(extract_flavor_details_for_wines).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------------------+\n",
      "|flavor_group|id     |wine_name              |\n",
      "+------------+-------+-----------------------+\n",
      "|oak         |4801829|Luiz Valduga Corte 1   |\n",
      "|black_fruit |4801829|Luiz Valduga Corte 1   |\n",
      "|red_fruit   |4801829|Luiz Valduga Corte 1   |\n",
      "|earth       |4801829|Luiz Valduga Corte 1   |\n",
      "|non_oak     |4801829|Luiz Valduga Corte 1   |\n",
      "|spices      |4801829|Luiz Valduga Corte 1   |\n",
      "|black_fruit |1964017|Gran Reserva           |\n",
      "|oak         |1964017|Gran Reserva           |\n",
      "|black_fruit |1638525|Seival Estate Sesmarias|\n",
      "|oak         |1638525|Seival Estate Sesmarias|\n",
      "+------------+-------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_flavors_df.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can *join()* two dataframes, also similar to sql. You can also register multiple temp tables and use spark sql for your joins: https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.join.html"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
